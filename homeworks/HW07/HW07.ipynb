{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0b8965d-b83f-4b2d-a8e2-12190649dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, adjusted_rand_score\n",
    "\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "ARTIFACTS_DIR = \"./artifacts\"\n",
    "FIGURES_DIR = \"./artifacts/figures\"\n",
    "\n",
    "os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(ARTIFACTS_DIR, \"labels\"), exist_ok=True)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6135df1-3e0e-47db-927f-498b8553a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(X, labels):\n",
    "    n_labels = len(set(labels))\n",
    "    noise_ratio = np.sum(labels == -1) / len(labels) if -1 in labels else 0.0\n",
    "    unique_labels_no_noise = set(labels) - {-1}\n",
    "    \n",
    "    if len(unique_labels_no_noise) < 2:\n",
    "        return {\n",
    "            \"silhouette\": np.nan,\n",
    "            \"davies_bouldin\": np.nan,\n",
    "            \"calinski_harabasz\": np.nan,\n",
    "            \"noise_ratio\": noise_ratio,\n",
    "            \"n_clusters\": len(unique_labels_no_noise)\n",
    "        }\n",
    "        \n",
    "    mask = labels != -1\n",
    "    X_clean = X[mask]\n",
    "    labels_clean = labels[mask]\n",
    "    \n",
    "    return {\n",
    "        \"silhouette\": silhouette_score(X_clean, labels_clean),\n",
    "        \"davies_bouldin\": davies_bouldin_score(X_clean, labels_clean),\n",
    "        \"calinski_harabasz\": calinski_harabasz_score(X_clean, labels_clean),\n",
    "        \"noise_ratio\": noise_ratio,\n",
    "        \"n_clusters\": len(unique_labels_no_noise)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b5a7dc8-0763-4fd1-99eb-cc7af4b92e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_clusters(X_processed, labels, title, filename):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_processed)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=10, alpha=0.7)\n",
    "    plt.title(f\"PCA Visualization: {title}\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.colorbar(scatter, label=\"Cluster Label\")\n",
    "    \n",
    "    save_path = os.path.join(FIGURES_DIR, filename)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Graph saved: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d01cb6-af67-4232-8597-bd4a96e3431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric_curve(param_values, metric_values, param_name, metric_name, title, filename):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(param_values, metric_values, marker='o')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(metric_name)\n",
    "    plt.grid(True)\n",
    "    \n",
    "    save_path = os.path.join(FIGURES_DIR, filename)\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2816847-5c18-4c52-b689-661b47a75d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringExperiment:\n",
    "    def __init__(self, dataset_name, file_name):\n",
    "        self.name = dataset_name\n",
    "        self.file_path = os.path.join(DATA_DIR, file_name)\n",
    "        self.df = None\n",
    "        self.X = None\n",
    "        self.X_processed = None\n",
    "        self.sample_ids = None\n",
    "        self.pipeline = None\n",
    "        self.results = [] \n",
    "        \n",
    "    def load_and_explore(self):\n",
    "        print(f\"\\n{'='*20} Loading {self.name} {'='*20}\")\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        \n",
    "        print(\"Shape:\", self.df.shape)\n",
    "        print(\"\\nMissing values:\\n\", self.df.isna().sum()[self.df.isna().sum() > 0])\n",
    "        print(\"\\nTypes:\\n\", self.df.dtypes)\n",
    "        display(self.df.head(3))\n",
    "        \n",
    "        if 'sample_id' in self.df.columns:\n",
    "            self.sample_ids = self.df['sample_id']\n",
    "            self.X = self.df.drop(columns=['sample_id'])\n",
    "        else:\n",
    "            self.sample_ids = self.df.index\n",
    "            self.X = self.df\n",
    "            \n",
    "    def build_pipeline(self, cat_cols=None):\n",
    "        num_cols = [c for c in self.X.columns if c not in (cat_cols or [])]\n",
    "        \n",
    "        num_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "        transformers = [('num', num_transformer, num_cols)]\n",
    "        \n",
    "        if cat_cols:\n",
    "            cat_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "            ])\n",
    "            transformers.append(('cat', cat_transformer, cat_cols))\n",
    "            \n",
    "        self.preprocessor = ColumnTransformer(transformers=transformers)\n",
    "        \n",
    "        self.X_processed = self.preprocessor.fit_transform(self.X)\n",
    "        print(f\"Preprocessing done. X shape: {self.X_processed.shape}\")\n",
    "        \n",
    "    def run_kmeans(self, k_range):\n",
    "        print(f\"Running KMeans for k={k_range}...\")\n",
    "        sil_scores = []\n",
    "        \n",
    "        for k in k_range:\n",
    "            model = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "            labels = model.fit_predict(self.X_processed)\n",
    "            metrics = calculate_metrics(self.X_processed, labels)\n",
    "            \n",
    "            res_entry = {\n",
    "                \"dataset\": self.name,\n",
    "                \"model\": \"KMeans\",\n",
    "                \"params\": {\"n_clusters\": k},\n",
    "                \"metrics\": metrics,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "            self.results.append(res_entry)\n",
    "            sil_scores.append(metrics['silhouette'])\n",
    "            \n",
    "        plot_metric_curve(k_range, sil_scores, \"k\", \"Silhouette\", \n",
    "                          f\"{self.name} - KMeans Silhouette\", \n",
    "                          f\"{self.name}_kmeans_sil.png\")\n",
    "\n",
    "    def run_dbscan(self, eps_range, min_samples=5):\n",
    "        print(f\"Running DBSCAN for eps={eps_range}...\")\n",
    "        sil_scores = []\n",
    "        \n",
    "        for eps in eps_range:\n",
    "            model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = model.fit_predict(self.X_processed)\n",
    "            metrics = calculate_metrics(self.X_processed, labels)\n",
    "            \n",
    "            res_entry = {\n",
    "                \"dataset\": self.name,\n",
    "                \"model\": \"DBSCAN\",\n",
    "                \"params\": {\"eps\": eps, \"min_samples\": min_samples},\n",
    "                \"metrics\": metrics,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "            self.results.append(res_entry)\n",
    "            sil_scores.append(metrics['silhouette'] if not np.isnan(metrics['silhouette']) else -1)\n",
    "            \n",
    "        plot_metric_curve(eps_range, sil_scores, \"eps\", \"Silhouette\", \n",
    "                          f\"{self.name} - DBSCAN Silhouette\", \n",
    "                          f\"{self.name}_dbscan_sil.png\")\n",
    "\n",
    "    def run_agglomerative(self, k_range, linkage='ward'):\n",
    "        print(f\"Running Agglomerative ({linkage}) for k={k_range}...\")\n",
    "        sil_scores = []\n",
    "        for k in k_range:\n",
    "            model = AgglomerativeClustering(n_clusters=k, linkage=linkage)\n",
    "            labels = model.fit_predict(self.X_processed)\n",
    "            metrics = calculate_metrics(self.X_processed, labels)\n",
    "            \n",
    "            res_entry = {\n",
    "                \"dataset\": self.name,\n",
    "                \"model\": f\"Agglomerative_{linkage}\",\n",
    "                \"params\": {\"n_clusters\": k, \"linkage\": linkage},\n",
    "                \"metrics\": metrics,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "            self.results.append(res_entry)\n",
    "            sil_scores.append(metrics['silhouette'])\n",
    "            \n",
    "        plot_metric_curve(k_range, sil_scores, \"k\", \"Silhouette\", \n",
    "                  f\"{self.name} - Agglomerative ({linkage}) Silhouette\", \n",
    "                  f\"{self.name}_agglo_{linkage}_sil.png\")\n",
    "\n",
    "    def save_best_solution(self, criteria='silhouette'):\n",
    "        valid_results = [r for r in self.results if not np.isnan(r['metrics'][criteria])]\n",
    "        \n",
    "        if not valid_results:\n",
    "            print(\"No valid results found.\")\n",
    "            return None\n",
    "\n",
    "        reverse = False if criteria == 'davies_bouldin' else True\n",
    "        best_res = sorted(valid_results, key=lambda x: x['metrics'][criteria], reverse=reverse)[0]\n",
    "        \n",
    "        print(f\"\\nBest solution for {self.name} based on {criteria}:\")\n",
    "        print(f\"Model: {best_res['model']}, Params: {best_res['params']}\")\n",
    "        print(f\"Metrics: {best_res['metrics']}\")\n",
    "        \n",
    "        plot_pca_clusters(self.X_processed, best_res['labels'], \n",
    "                          f\"{self.name} Best: {best_res['model']}\", \n",
    "                          f\"{self.name}_best_pca.png\")\n",
    "        \n",
    "        labels_df = pd.DataFrame({\n",
    "            'sample_id': self.sample_ids,\n",
    "            'cluster_label': best_res['labels']\n",
    "        })\n",
    "        labels_path = os.path.join(ARTIFACTS_DIR, \"labels\", f\"labels_{self.name}.csv\")\n",
    "        labels_df.to_csv(labels_path, index=False)\n",
    "        print(f\"Labels saved to {labels_path}\")\n",
    "        \n",
    "        return best_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413f0d33-bbe8-478a-bb68-78cbeb0ca80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Loading dataset_01 ====================\n",
      "Shape: (12000, 9)\n",
      "\n",
      "Missing values:\n",
      " Series([], dtype: int64)\n",
      "\n",
      "Types:\n",
      " sample_id      int64\n",
      "f01          float64\n",
      "f02          float64\n",
      "f03          float64\n",
      "f04          float64\n",
      "f05          float64\n",
      "f06          float64\n",
      "f07          float64\n",
      "f08          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>f01</th>\n",
       "      <th>f02</th>\n",
       "      <th>f03</th>\n",
       "      <th>f04</th>\n",
       "      <th>f05</th>\n",
       "      <th>f06</th>\n",
       "      <th>f07</th>\n",
       "      <th>f08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.536647</td>\n",
       "      <td>-69.812900</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>71.743147</td>\n",
       "      <td>-11.396498</td>\n",
       "      <td>-12.291287</td>\n",
       "      <td>-6.836847</td>\n",
       "      <td>-0.504094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15.230731</td>\n",
       "      <td>52.727216</td>\n",
       "      <td>-1.273634</td>\n",
       "      <td>-104.123302</td>\n",
       "      <td>11.589643</td>\n",
       "      <td>34.316967</td>\n",
       "      <td>-49.468873</td>\n",
       "      <td>0.390356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18.542693</td>\n",
       "      <td>77.317150</td>\n",
       "      <td>-1.321686</td>\n",
       "      <td>-111.946636</td>\n",
       "      <td>10.254346</td>\n",
       "      <td>25.892951</td>\n",
       "      <td>44.595250</td>\n",
       "      <td>0.325893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id        f01        f02       f03         f04        f05  \\\n",
       "0          0  -0.536647 -69.812900 -0.002657   71.743147 -11.396498   \n",
       "1          1  15.230731  52.727216 -1.273634 -104.123302  11.589643   \n",
       "2          2  18.542693  77.317150 -1.321686 -111.946636  10.254346   \n",
       "\n",
       "         f06        f07       f08  \n",
       "0 -12.291287  -6.836847 -0.504094  \n",
       "1  34.316967 -49.468873  0.390356  \n",
       "2  25.892951  44.595250  0.325893  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done. X shape: (12000, 8)\n",
      "Running KMeans for k=range(2, 11)...\n",
      "Running DBSCAN for eps=[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4]...\n",
      "\n",
      "Best solution for dataset_01 based on silhouette:\n",
      "Model: KMeans, Params: {'n_clusters': 2}\n",
      "Metrics: {'silhouette': 0.5216395622404242, 'davies_bouldin': 0.6853295219054459, 'calinski_harabasz': 11786.954622671528, 'noise_ratio': 0.0, 'n_clusters': 2}\n",
      "Graph saved: ./artifacts/figures/dataset_01_best_pca.png\n",
      "Labels saved to ./artifacts/labels/labels_dataset_01.csv\n"
     ]
    }
   ],
   "source": [
    "DS1_FILE = \"S07-hw-dataset-01.csv\" \n",
    "\n",
    "exp1 = ClusteringExperiment(\"dataset_01\", DS1_FILE)\n",
    "exp1.load_and_explore()\n",
    "exp1.build_pipeline()\n",
    "\n",
    "exp1.run_kmeans(range(2, 11))\n",
    "exp1.run_dbscan(np.arange(0.1, 1.5, 0.1), min_samples=5)\n",
    "\n",
    "best1 = exp1.save_best_solution(criteria='silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c72fd2-2be6-4120-96eb-fe4d9150f505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Loading dataset_02 ====================\n",
      "Shape: (8000, 4)\n",
      "\n",
      "Missing values:\n",
      " Series([], dtype: int64)\n",
      "\n",
      "Types:\n",
      " sample_id      int64\n",
      "x1           float64\n",
      "x2           float64\n",
      "z_noise      float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>z_noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.098849</td>\n",
       "      <td>-1.846034</td>\n",
       "      <td>21.288122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.024516</td>\n",
       "      <td>1.829616</td>\n",
       "      <td>6.072952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.094178</td>\n",
       "      <td>-0.158545</td>\n",
       "      <td>-18.938342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id        x1        x2    z_noise\n",
       "0          0  0.098849 -1.846034  21.288122\n",
       "1          1 -1.024516  1.829616   6.072952\n",
       "2          2 -1.094178 -0.158545 -18.938342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done. X shape: (8000, 3)\n",
      "Running KMeans for k=range(2, 10)...\n",
      "Running DBSCAN for eps=[0.1  0.15 0.2  0.25 0.3  0.35 0.4  0.45 0.5  0.55 0.6  0.65 0.7  0.75]...\n",
      "Running Agglomerative (single) for k=range(2, 10)...\n",
      "\n",
      "Best solution for dataset_02 based on silhouette:\n",
      "Model: Agglomerative_single, Params: {'n_clusters': 2, 'linkage': 'single'}\n",
      "Metrics: {'silhouette': 0.5213161442555723, 'davies_bouldin': 0.34186056281280663, 'calinski_harabasz': 7.184330110542804, 'noise_ratio': 0.0, 'n_clusters': 2}\n",
      "Graph saved: ./artifacts/figures/dataset_02_best_pca.png\n",
      "Labels saved to ./artifacts/labels/labels_dataset_02.csv\n"
     ]
    }
   ],
   "source": [
    "DS2_FILE = \"S07-hw-dataset-02.csv\"\n",
    "\n",
    "exp2 = ClusteringExperiment(\"dataset_02\", DS2_FILE)\n",
    "exp2.load_and_explore()\n",
    "exp2.build_pipeline()\n",
    "\n",
    "exp2.run_kmeans(range(2, 10))\n",
    "\n",
    "exp2.run_dbscan(np.arange(0.1, 0.8, 0.05), min_samples=5)\n",
    "\n",
    "exp2.run_agglomerative(range(2, 10), linkage='single')\n",
    "\n",
    "best2 = exp2.save_best_solution(criteria='silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d52c908-fcf7-467f-b843-b90467db2cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Loading dataset_04 ====================\n",
      "Shape: (10000, 33)\n",
      "\n",
      "Missing values:\n",
      " n01    174\n",
      "n02    189\n",
      "n03    199\n",
      "n04    192\n",
      "n05    201\n",
      "n06    183\n",
      "n07    204\n",
      "n08    194\n",
      "n09    195\n",
      "n10    189\n",
      "n11    204\n",
      "n12    202\n",
      "n13    197\n",
      "n14    198\n",
      "n15    186\n",
      "n16    191\n",
      "n17    212\n",
      "n18    212\n",
      "n19    187\n",
      "n20    203\n",
      "n21    215\n",
      "n22    196\n",
      "n23    171\n",
      "n24    207\n",
      "n25    185\n",
      "n26    224\n",
      "n27    197\n",
      "n28    211\n",
      "n29    202\n",
      "n30    195\n",
      "dtype: int64\n",
      "\n",
      "Types:\n",
      " sample_id      int64\n",
      "cat_a         object\n",
      "cat_b         object\n",
      "n01          float64\n",
      "n02          float64\n",
      "n03          float64\n",
      "n04          float64\n",
      "n05          float64\n",
      "n06          float64\n",
      "n07          float64\n",
      "n08          float64\n",
      "n09          float64\n",
      "n10          float64\n",
      "n11          float64\n",
      "n12          float64\n",
      "n13          float64\n",
      "n14          float64\n",
      "n15          float64\n",
      "n16          float64\n",
      "n17          float64\n",
      "n18          float64\n",
      "n19          float64\n",
      "n20          float64\n",
      "n21          float64\n",
      "n22          float64\n",
      "n23          float64\n",
      "n24          float64\n",
      "n25          float64\n",
      "n26          float64\n",
      "n27          float64\n",
      "n28          float64\n",
      "n29          float64\n",
      "n30          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>cat_a</th>\n",
       "      <th>cat_b</th>\n",
       "      <th>n01</th>\n",
       "      <th>n02</th>\n",
       "      <th>n03</th>\n",
       "      <th>n04</th>\n",
       "      <th>n05</th>\n",
       "      <th>n06</th>\n",
       "      <th>n07</th>\n",
       "      <th>...</th>\n",
       "      <th>n21</th>\n",
       "      <th>n22</th>\n",
       "      <th>n23</th>\n",
       "      <th>n24</th>\n",
       "      <th>n25</th>\n",
       "      <th>n26</th>\n",
       "      <th>n27</th>\n",
       "      <th>n28</th>\n",
       "      <th>n29</th>\n",
       "      <th>n30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>X</td>\n",
       "      <td>-4.827501</td>\n",
       "      <td>-24.507466</td>\n",
       "      <td>-7.852963</td>\n",
       "      <td>0.771781</td>\n",
       "      <td>28.297884</td>\n",
       "      <td>-4.493911</td>\n",
       "      <td>-42.769449</td>\n",
       "      <td>...</td>\n",
       "      <td>24.597176</td>\n",
       "      <td>-26.354320</td>\n",
       "      <td>4.543397</td>\n",
       "      <td>-19.549036</td>\n",
       "      <td>-3.051332</td>\n",
       "      <td>-5.538587</td>\n",
       "      <td>-3.084457</td>\n",
       "      <td>5.499629</td>\n",
       "      <td>-6.128896</td>\n",
       "      <td>3.132067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>V</td>\n",
       "      <td>51.302500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.534737</td>\n",
       "      <td>51.305464</td>\n",
       "      <td>-8.027553</td>\n",
       "      <td>28.297548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.216260</td>\n",
       "      <td>8.527932</td>\n",
       "      <td>17.202115</td>\n",
       "      <td>-30.452260</td>\n",
       "      <td>0.855326</td>\n",
       "      <td>1.199066</td>\n",
       "      <td>3.597555</td>\n",
       "      <td>-2.239703</td>\n",
       "      <td>2.932710</td>\n",
       "      <td>0.473145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>-4.820828</td>\n",
       "      <td>-2.625385</td>\n",
       "      <td>27.891578</td>\n",
       "      <td>1.523041</td>\n",
       "      <td>-5.776687</td>\n",
       "      <td>-16.298523</td>\n",
       "      <td>2.462937</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.260775</td>\n",
       "      <td>9.313232</td>\n",
       "      <td>12.323411</td>\n",
       "      <td>55.081325</td>\n",
       "      <td>-3.945606</td>\n",
       "      <td>-0.280540</td>\n",
       "      <td>-0.130583</td>\n",
       "      <td>-7.353205</td>\n",
       "      <td>-2.942836</td>\n",
       "      <td>1.460477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id cat_a cat_b        n01        n02        n03        n04  \\\n",
       "0          0     B     X  -4.827501 -24.507466  -7.852963   0.771781   \n",
       "1          1     F     V  51.302500        NaN   5.534737  51.305464   \n",
       "2          2     A     W  -4.820828  -2.625385  27.891578   1.523041   \n",
       "\n",
       "         n05        n06        n07  ...        n21        n22        n23  \\\n",
       "0  28.297884  -4.493911 -42.769449  ...  24.597176 -26.354320   4.543397   \n",
       "1  -8.027553  28.297548        NaN  ... -18.216260   8.527932  17.202115   \n",
       "2  -5.776687 -16.298523   2.462937  ... -48.260775   9.313232  12.323411   \n",
       "\n",
       "         n24       n25       n26       n27       n28       n29       n30  \n",
       "0 -19.549036 -3.051332 -5.538587 -3.084457  5.499629 -6.128896  3.132067  \n",
       "1 -30.452260  0.855326  1.199066  3.597555 -2.239703  2.932710  0.473145  \n",
       "2  55.081325 -3.945606 -0.280540 -0.130583 -7.353205 -2.942836  1.460477  \n",
       "\n",
       "[3 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns detected: ['cat_a', 'cat_b']\n",
      "Preprocessing done. X shape: (10000, 42)\n",
      "Running KMeans for k=range(2, 15)...\n",
      "Running Agglomerative (ward) for k=range(2, 15)...\n",
      "\n",
      "Best solution for dataset_04 based on silhouette:\n",
      "Model: KMeans, Params: {'n_clusters': 5}\n",
      "Metrics: {'silhouette': 0.44736887827969146, 'davies_bouldin': 0.975904265483746, 'calinski_harabasz': 5087.688517434967, 'noise_ratio': 0.0, 'n_clusters': 5}\n",
      "Graph saved: ./artifacts/figures/dataset_04_best_pca.png\n",
      "Labels saved to ./artifacts/labels/labels_dataset_04.csv\n"
     ]
    }
   ],
   "source": [
    "DS4_FILE = \"S07-hw-dataset-04.csv\"\n",
    "\n",
    "exp4 = ClusteringExperiment(\"dataset_04\", DS4_FILE)\n",
    "exp4.load_and_explore()\n",
    "\n",
    "cat_cols = exp4.X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(\"Categorical columns detected:\", cat_cols)\n",
    "\n",
    "exp4.build_pipeline(cat_cols=cat_cols)\n",
    "\n",
    "exp4.run_kmeans(range(2, 15))\n",
    "exp4.run_agglomerative(range(2, 15), linkage='ward')\n",
    "\n",
    "best4 = exp4.save_best_solution(criteria='silhouette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a077ff0d-0fe7-4b6f-b99a-34cbeef02c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability check for Dataset 01 (KMeans)\n",
      "Seed 10: ARI = 1.0000\n",
      "Seed 20: ARI = 1.0000\n",
      "Seed 30: ARI = 1.0000\n",
      "Seed 40: ARI = 1.0000\n",
      "Seed 50: ARI = 1.0000\n",
      "Average Stability (ARI): 1.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"Stability check for Dataset 01 (KMeans)\")\n",
    "\n",
    "stability_scores = []\n",
    "base_model = KMeans(n_clusters=3, n_init=10, random_state=42)\n",
    "base_labels = base_model.fit_predict(exp1.X_processed)\n",
    "\n",
    "for seed in [10, 20, 30, 40, 50]:\n",
    "    comp_model = KMeans(n_clusters=3, n_init=10, random_state=seed)\n",
    "    comp_labels = comp_model.fit_predict(exp1.X_processed)\n",
    "    \n",
    "    ari = adjusted_rand_score(base_labels, comp_labels)\n",
    "    stability_scores.append(ari)\n",
    "    print(f\"Seed {seed}: ARI = {ari:.4f}\")\n",
    "\n",
    "print(f\"Average Stability (ARI): {np.mean(stability_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "877c7a5d-418f-475b-abb3-c33e2055333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_best = [best1, best2, best4]\n",
    "summary_data = {}\n",
    "\n",
    "for item in all_best:\n",
    "    if item:\n",
    "        summary_data[item['dataset']] = {\n",
    "            \"best_model\": item['model'],\n",
    "            \"best_params\": item['params'],\n",
    "            \"metrics\": item['metrics']\n",
    "        }\n",
    "\n",
    "with open(os.path.join(ARTIFACTS_DIR, \"metrics_summary.json\"), \"w\") as f:\n",
    "    json.dump(summary_data, f, indent=4)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
