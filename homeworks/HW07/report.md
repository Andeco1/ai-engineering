# HW07 – Report

> Файл: `homeworks/HW07/report.md`
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset 01

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: Все числовые (`float64`), 8 признаков (`f01`...`f08`).
- Пропуски: нет.
- "Подлости" датасета: Признаки имеют разные диапазоны значений (требуется масштабирование). Судя по PCA, структура кластеров глобулярная, но они расположены на разном расстоянии друг от друга.

### 1.2 Dataset 02

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбца)
- Признаки: Числовые (`x1`, `x2`, `z_noise`).
- Пропуски: нет.
- "Подлости" датасета: Наличие шумового признака `z_noise`. Нелинейная/геометрическая структура (KMeans тут обычно проигрывает).

### 1.3 Dataset 04

- Файл: `S07-hw-dataset-04.csv`
- Размер: (10000 строк, 33 столбца)
- Признаки: Смешанные. 30 числовых (`n01`...`n30`) и 2 категориальных (`cat_a`, `cat_b`).
- Пропуски: Есть во всех числовых признаках (около 200 пропусков на столбец).
- "Подлости" датасета: Необходимость кодирования категорий (OHE) и импутации пропусков. Высокая размерность после кодирования (42 признака).

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- **Препроцессинг:** Использовался `sklearn Pipeline` для предотвращения утечек:
  - Числовые данные: `SimpleImputer(strategy='median')` -> `StandardScaler`. Масштабирование критично для корректной работы евклидовых метрик.
  - Категориальные данные (Dataset 04): `SimpleImputer(strategy='constant')` -> `OneHotEncoder(handle_unknown='ignore')`.
- **Поиск гиперпараметров:**
  - **KMeans:** перебор `k` в диапазоне от 2 до 15.
  - **DBSCAN:** перебор `eps` с шагом 0.05-0.1, фиксированный `min_samples=5`.
  - **Agglomerative:** перебор `k` (2-15) и `linkage` ('ward' для шарообразных, 'single' для вытянутых структур).
  - **Критерий выбора:** Основной ориентир — максимизация `silhouette_score`. Если значения были близки, учитывался `calinski_harabasz_score` и визуальная адекватность на PCA.
- **Метрики:** рассчитывались `silhouette_score`, `davies_bouldin_score` (чем меньше, тем лучше), `calinski_harabasz_score`. Для DBSCAN метрики считались только на очищенных от шума данных (label != -1).
- **Визуализация:** PCA(2D) использовался для проверки качества разделения лучшей модели.

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- **Dataset 01:**
  - KMeans (`k`=2..10, `n_init`=10, `random_state`=42).
  - DBSCAN (`eps`=0.1..1.4, `min_samples`=5).

- **Dataset 02:**
  - KMeans (`k`=2..10).
  - DBSCAN (`eps`=0.1..0.75).
  - AgglomerativeClustering (`k`=2..10, `linkage`='single' — так как ожидалась сложная геометрия).

- **Dataset 04:**
  - KMeans (`k`=2..15).
  - AgglomerativeClustering (`k`=2..15, `linkage`='ward').

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset 01

- **Лучший метод и параметры:** KMeans (`n_clusters`=2).
- **Метрики:**
  - Silhouette: 0.522
  - Davies-Bouldin: 0.685
  - Calinski-Harabasz: 11786.95
- **Комментарий:** KMeans показал наивысший силуэт при k=2. На графике PCA видно четкое разделение на две большие группы (одна плотная, другая — более разреженная группа из трех "облаков"). Хотя визуально можно было бы выделить 4 кластера, с точки зрения плотности и межкластерного расстояния метрика предпочла 2.

### 4.2 Dataset 02

- **Лучший метод и параметры:** AgglomerativeClustering (`n_clusters`=2, `linkage`='single').
- **Метрики:**
  - Silhouette: 0.521
  - Davies-Bouldin: 0.342
  - Calinski-Harabasz: 7.18
- **Если был DBSCAN:** DBSCAN запускался, но показал нестабильный силуэт (скачки от -0.2 до +0.2).
- **Коротко:** KMeans провалился (силуэт падал с ростом k). Agglomerative с linkage='single' отлично справился с нелинейной структурой ("chaining effect"), разделив данные на два сложных, но плотных множества, что видно на PCA.

### 4.3 Dataset 04

- **Лучший метод и параметры:** KMeans (`n_clusters`=5).
- **Метрики:**
  - Silhouette: 0.447
  - Davies-Bouldin: 0.976
  - Calinski-Harabasz: 5087.69
- **Коротко:** И KMeans, и Agglomerative (Ward) показали пик силуэта при k=5. PCA визуализация демонстрирует 5 идеально разделенных, компактных кластеров. Это "школьный" пример удачной кластеризации.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- **Где KMeans "ломается":** На Dataset 02. Из-за своей природы (стремление минимизировать внутрикластерную дисперсию, создание выпуклых "сферических" кластеров) он не смог корректно разделить геометрически сложные структуры, отдав предпочтение Agglomerative Clustering с 'single' linkage.
- **Преимущество иерархической кластеризации:** Linkage='single' сработал как аналог DBSCAN, но с возможностью задать явное число кластеров, что помогло на Dataset 02.
- **Влияние препроцессинга:** Для Dataset 04 критическим была обработка пропусков (`SimpleImputer`). Без масштабирования (`StandardScaler`) на Dataset 01 KMeans сходился бы гораздо хуже или давал неверные границы из-за разницы в дисперсиях признаков.

### 5.2 Устойчивость (Dataset 01)

- **Проверка:** 5 запусков KMeans с разными `random_state` (seeds: 10, 20, 30, 40, 50) на Dataset 01. Сравнение производилось через Adjusted Rand Index (ARI).
- **Результат:** ARI = 1.0000 во всех 5 случаях.
- **Вывод:** Решение абсолютно устойчиво. Структура данных (даже при разделении на 2 крупных кластера) настолько очевидна для алгоритма, что случайная инициализация центроидов не влияет на финальный результат.

### 5.3 Интерпретация кластеров

- **Dataset 04:** PCA показал 5 изолированных облаков. Интерпретация может строиться на комбинации категориальных признаков `cat_a`/`cat_b`. Скорее всего, каждый кластер соответствует определенному шаблону поведения пользователей или типу объектов, закодированному в этих категориях, подкрепленному диапазонами числовых значений.
- **Dataset 01:** Разделение на k=2, вероятно, отделяет "основную массу" от "фоновой" или другой глобальной группы, несмотря на то, что внутри одной из групп есть подструктуры.

## 6. Conclusion

1. **StandardScaler обязателен** для всех метрических алгоритмов (KMeans, DBSCAN, Agglomerative), иначе признаки с большими значениями доминируют.
2. **Silhouette Score не панацея:** он поощряет выпуклые кластеры. На Dataset 02 (нелинейность) нужно смотреть глазами (PCA) или использовать другие критерии, так как KMeans может иметь неплохой силуэт, но разрезать "банан" пополам.
3. **Pipeline спасает от ошибок:** использование пайплайнов для импутации и скейлинга гарантирует, что одни и те же преобразования применяются корректно при любых экспериментах.
4. **Важность визуализации:** Цифры метрик (например, Sil=0.52 на DS1 и DS2) могут выглядеть одинаково, но стоять за ними могут совершенно разные геометрические структуры (глобулы vs сложные формы).