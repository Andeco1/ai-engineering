# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-02.csv`
- Размер: (18000, 39)
- Целевая переменная: `target` 
        Класс 0: ~73.7%
        Класс 1: ~26.3%
- Признаки: 37 числовые признаки (f01...f37), тип float64

## 2. Protocol

- Разбиение: train/test 13500/4500 random_state=15
        Train: 13500 объектов.
        Test: 4500 объектов.
        Параметры: test_size=0.25, random_state=15, stratify=y.
- Подбор: CV на train 
    Использовалась кросс-валидация StratifiedKFold, 5 фолдов на train.
    Метрика оптимизации: ROC-AUC.
- Метрики: accuracy, F1, ROC-AUC
    ROC-AUC основная, так как оцениваем способность ранжировать классы.
    F1-score важна из-за дисбаланса, чтобы не игнорировать минорный класс 1.
    Accuracy справочно.

## 3. Models

Сравнивались следующие модели с подбором параметров на Train:
    DummyClassifier: Baseline (стратегия most_frequent).
    LogisticRegression:
        Лучшие параметры: C=10.
    DecisionTreeClassifier:
        Лучшие параметры: max_depth=10, min_samples_leaf=10, ccp_alpha=0.0.
        Дерево ограничили по глубине, чтобы избежать переобучения.
    RandomForestClassifier:
        Лучшие параметры: n_estimators=100, max_depth=None, min_samples_leaf=1.
        Полноценный лес без ограничения глубины.
    GradientBoostingClassifier:
        Лучшие параметры: n_estimators=100, learning_rate=0.2, max_depth=5.

- DummyClassifier (baseline)
- LogisticRegression (baseline из S05)
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)
- RandomForestClassifier
- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting)

Опционально:

- StackingClassifier (с CV-логикой)

## 4. Results

- Таблица/список финальных метрик на test по всем моделям

| Model            | Accuracy | F1 Score | ROC-AUC |
|------------------|----------|----------|---------|
| Dummy            | 0.74     | 0.00     | 0.50    |
| LogReg           | 0.81     | 0.55     | 0.79    |
| DecisionTree     | 0.84     | 0.67     | 0.82    |
| RandomForest     | 0.89     | 0.74     | 0.923   |
| GradientBoosting | 0.89     | 0.77     | 0.92    |

- Победитель: Формально по критерию ROC-AUC победил RandomForest (0.923). Однако стоит отметить, что GradientBoosting показал практически такой же ROC-AUC (0.922), но при этом заметно выиграл по F1-score.

## 5. Analysis

Устойчивость: Сравнение best_cv_score (на обучающей выборке) и метрик на test показывает минимальный разрыв (для RandomForest: 0.926 vs 0.923 ROC-AUC). Это свидетельствует о высокой стабильности модели. При изменении random_state результаты ансамблей (RF, GradientBoosting) будут колебаться незначительно (в пределах 1–2%), так как большое количество деревьев (100 штук) эффективно усредняет случайный шум выборки.

Ошибки (Confusion Matrix): Анализ матрицы для лучшей модели (RandomForest) показывает:
    True Negatives (3257): Модель почти безошибочно определяет основной класс "0".
    False Positives (61): Очень низкое количество ложных срабатываний.
    False Negatives (452): Основная проблема модели — пропуск объектов класса "1". 
Почти 38% объектов целевого класса (452 из 1182) не были распознаны, что объясняет более низкий показатель F1 (0.74) при высоком ROC-AUC (0.92).

Интерпретация (Permutation Importance): Согласно графику важности признаков:
    Абсолютным лидером влияния на прогноз является признак f16 (важность > 0.06), за ним следует f01.
    Признаки f12, f19, f30 имеют схожий средний уровень влияния.

Вывод: Модель сильно опирается на небольшую группу ключевых признаков. Удаление или зашумление признака f16 приведет к наиболее существенному падению качества классификации.

## 6. Conclusion

Превосходство ансамблей: Сложные ансамбли (Gradient Boosting и Random Forest) значительно опережают одиночное дерево решений и логистическую регрессию, давая прирост ROC-AUC более чем на 0.10.

Специфика моделей: Хотя по ROC-AUC победил Random Forest (0.923), модель Gradient Boosting показала лучший F1-score (0.77) и Accuracy (0.89), что делает её более сбалансированной для практического применения при данном пороге классификации.

Борьба с переобучением: Подбор параметров (например, max_depth: 10 для DecisionTree или min_samples_leaf: 10) позволил удержать сложность моделей в рамках, обеспечив высокую обобщающую способность на тестовых данных.

